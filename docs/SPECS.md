# File Sync - Zero Knowledge E2EE

Synchronisation de fichiers entre 3-4 machines (Windows/macOS/Linux) avec chiffrement c√¥t√© client et stockage de blocs chiffr√©s sur block storage externe.

## Contexte
- **Machines:** 3-4 (Windows, macOS, Linux)
- **Usage:** Modifications simultan√©es fr√©quentes sur plusieurs machines
- **Fichiers:** Tailles tr√®s variables (petits docs ‚Üí gros fichiers)
- **S√©curit√©:** Zero-Knowledge - le serveur ne voit JAMAIS les donn√©es en clair
- **Transport:** HTTPS (plus besoin de SSH car E2EE)

---

## Requirements Fonctionnels

### R1. Synchronisation
- [ ] Sync bidirectionnel entre machines (via serveur)
- [ ] D√©tection automatique des changements locaux (file watcher + scan backup 5min)
- [ ] Sync incr√©mental (ne pas re-uploader les fichiers inchang√©s)
- [ ] Content-Defined Chunking (CDC) pour delta sync optimis√© (insertions/modifications)
- [ ] Support fichiers de toutes tailles
- [ ] Debounce events : 250ms (coalescing multiple events)
- [ ] D√©lai avant sync : 3s apr√®s derni√®re modification
- [ ] Sync initiale : dossier local DOIT √™tre vide (download complet du remote)
- [ ] D√©tection des renommages via hash des blocs (pas de retransmission)
- [ ] Paths/noms de fichiers NON chiffr√©s (permet recherche dans Web UI)
- [ ] Streaming : lecture/√©criture chunk par chunk (max 8 MB en RAM)
- [ ] Resume apr√®s interruption : reprend √† partir des chunks manquants
- [ ] Int√©grit√© : hash SHA-256 v√©rifi√© √† chaque chunk (upload et download)

### R2. Chiffrement (E2EE)
- [ ] Chiffrement c√¥t√© client uniquement
- [ ] Serveur ne voit jamais les donn√©es en clair
- [ ] Cl√© d√©riv√©e d'un mot de passe ma√Ætre
- [ ] Partage de cl√© entre machines (export/import)
- [ ] Algorithme robuste (AES-GCM ou ChaCha20)

### R3. Gestion des conflits
- [ ] D√©tection automatique des conflits
- [ ] Strat√©gie : duplication des fichiers conflictuels
- [ ] Nommage clair : `fichier (conflit - machine).ext`
- [ ] R√©solution manuelle par l'utilisateur

### R4. Stockage
- [ ] Block storage externe (S3-compatible)
- [ ] Mode local FS pour dev/test
- [ ] Chunks li√©s exclusivement √† leur fichier (pas de d√©duplication v1)
- [ ] Suppression des chunks √† la purge de corbeille (simple, pas de GC complexe)
- [ ] Note : D√©duplication inter-fichiers pr√©vue ult√©rieurement (v2)

### R4bis. Corbeille (fichiers supprim√©s)
- [ ] Fichiers supprim√©s conserv√©s X jours (configurable, d√©faut 30j)
- [ ] Page d√©di√©e dans Web UI pour consulter la corbeille
- [ ] Restauration possible depuis Web UI
- [ ] Purge automatique apr√®s expiration
- [ ] Note : syst√®me de backup complet pr√©vu ult√©rieurement

### R5. Client local
- [ ] Daemon en arri√®re-plan
- [ ] File watcher (d√©tection changements)
- [ ] Tray icon avec statut
- [ ] CLI pour configuration et debug
- [ ] Protocol handler (`syncfile://`) pour ouvrir fichiers depuis Web UI
- [ ] Cross-platform (Windows, macOS, Linux)

### R6. Serveur
- [ ] API REST pour m√©tadonn√©es
- [ ] Stockage m√©tadonn√©es uniquement (Zero Knowledge)
- [ ] Pas d'historique de versions (derni√®re version uniquement pour √©conomie stockage)
- [ ] D√©tection et signalement des conflits
- [ ] Note : backup complet pr√©vu ult√©rieurement (ind√©pendant du versioning)

### R7. Web UI
- [ ] File browser (m√©tadonn√©es seulement)
- [ ] Recherche par nom de fichier/dossier
- [ ] Vue des conflits
- [ ] Statut des machines
- [ ] Page Corbeille (fichiers supprim√©s) avec restauration
- [ ] Responsive (mobile-friendly)

### R8. Authentification
- [ ] Auth machines : token Bearer
- [ ] Auth Web UI : session cookie (HttpOnly, Secure, SameSite=Strict)
- [ ] Tokens stock√©s hash√©s c√¥t√© serveur
- [ ] Compte admin unique cr√©√© via setup wizard (premi√®re visite Web UI)
- [ ] Mot de passe admin : minimum 14 caract√®res
- [ ] Protection CSRF (token dans formulaires)
- [ ] Session expiration : 24h (configurable)
- [ ] Note : Rate limiting g√©r√© en amont (nginx/reverse proxy)

### R9. Sync temps r√©el (WebSocket client ‚Üî serveur)
- [ ] Connexion WebSocket permanente du daemon client au serveur
- [ ] Push notification quand un autre client upload un fichier
- [ ] Sync quasi-instantan√©e entre machines (< 5s)
- [ ] Reconnexion automatique avec backoff exponentiel
- [ ] Heartbeat pour d√©tecter d√©connexions
- [ ] Note : Web UI sans WebSocket (refresh manuel suffit)

### R10. Enregistrement machines
- [ ] Nom unique par machine
- [ ] Validation format nom (alphanum, tirets, underscores)
- [ ] G√©n√©ration token √† l'enregistrement
- [ ] Workflow premi√®re machine vs machines suivantes
- [ ] Invitation token (usage unique, expire en 24h)
- [ ] G√©n√©ration des invitations via Web UI uniquement
- [ ] Admin peut voir/r√©voquer les invitations en attente

### R11. Gestion du master password
- [ ] D√©rivation cl√© via Argon2id (r√©sistant brute-force)
- [ ] Deux cl√©s : master_key (d√©riv√©e) + encryption_key (al√©atoire)
- [ ] Changement de password sans re-chiffrer les fichiers
- [ ] Stockage cl√© : keyring OS par d√©faut (Windows Credential Manager / macOS Keychain / Linux Secret Service)
- [ ] Mode "prompt" optionnel (demande password √† chaque d√©marrage)
- [ ] Commandes : `unlock`, `lock`, `change-password`

---

## Requirements Non-Fonctionnels

### R12. Qualit√© du code (niveau senior)
- [ ] Code coverage ‚â• 95% pour le client (hors tray icon)
- [ ] Code coverage ‚â• 95% pour le serveur (hors templates Web UI)
- [ ] Tests d'int√©gration client ‚Üî serveur
- [ ] Linting : ruff (zero warnings)
- [ ] Type checking : mypy strict
- [ ] Commits fr√©quents respectant [Conventional Commits](https://www.conventionalcommits.org/)
  - `feat:` nouvelle fonctionnalit√©
  - `fix:` correction de bug
  - `refactor:` refactoring sans changement fonctionnel
  - `test:` ajout/modification de tests
  - `docs:` documentation
  - `chore:` maintenance (deps, config, CI)

### R13. Best practices (niveau senior)
- [ ] SOLID principles
- [ ] DRY (Don't Repeat Yourself)
- [ ] Separation of concerns (couches distinctes : API, business logic, data)
- [ ] Dependency injection pour testabilit√©
- [ ] Configuration externalis√©e (pas de hardcoding)
- [ ] Logging structur√© avec niveaux (DEBUG, INFO, WARNING, ERROR)
- [ ] Gestion d'erreurs explicite (pas de `except: pass`)
- [ ] Docstrings pour les fonctions publiques
- [ ] Code auto-document√© (noms explicites, pas de magic numbers)
- [ ] Tests : unitaires, int√©gration, et edge cases
- [ ] Revue de code avant merge (si applicable)

---

## 1. Architecture Zero-Knowledge

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         BLOCK STORAGE                           ‚îÇ
‚îÇ                     (OVH S3 / Swift / Ceph)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Blocs chiffr√©s uniquement - illisibles sans cl√© client         ‚îÇ
‚îÇ  /{user_id}/{chunk_hash}.enc                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñ≤
                              ‚îÇ HTTPS (blocs chiffr√©s)
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SERVEUR M√âTADONN√âES                        ‚îÇ
‚îÇ                    (FastAPI + SQLite WAL)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  NE STOCKE QUE :                                                ‚îÇ
‚îÇ  - Arborescence des fichiers                                    ‚îÇ
‚îÇ  - Hash des blocs (pas le contenu)                              ‚îÇ
‚îÇ  - Versions et branches                                         ‚îÇ
‚îÇ  - Conflits d√©tect√©s                                            ‚îÇ
‚îÇ  - M√©tadonn√©es machines                                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  NE VOIT JAMAIS :                                               ‚îÇ
‚îÇ  - Le contenu des fichiers                                      ‚îÇ
‚îÇ  - Les cl√©s de chiffrement                                      ‚îÇ
‚îÇ  - Les blocs d√©chiffr√©s                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚ñ≤
                              ‚îÇ HTTPS (m√©tadonn√©es + blocs chiffr√©s)
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       CLIENT LOCAL                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  SEUL ENDROIT O√ô :                                              ‚îÇ
‚îÇ  - Les fichiers sont en clair                                   ‚îÇ
‚îÇ  - Le chiffrement/d√©chiffrement a lieu                          ‚îÇ
‚îÇ  - La cl√© E2EE existe                                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Composants :                                                   ‚îÇ
‚îÇ  - File watcher (watchdog)                                      ‚îÇ
‚îÇ  - Moteur de chiffrement (AES-GCM)                              ‚îÇ
‚îÇ  - Content-Defined Chunking (CDC)                               ‚îÇ
‚îÇ  - SQLite local                                                 ‚îÇ
‚îÇ  - Tray icon (pystray)                                          ‚îÇ
‚îÇ  - Protocol handler (syncfile://)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Mod√®le de S√©curit√©

### 2.1 S√©paration des cl√©s
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Token Auth    ‚îÇ     ‚îÇ    Cl√© E2EE     ‚îÇ
‚îÇ   (HTTPS API)   ‚îÇ     ‚îÇ   (locale)      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Authentifie     ‚îÇ     ‚îÇ Chiffre les     ‚îÇ
‚îÇ le client       ‚îÇ     ‚îÇ donn√©es         ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ Permet :        ‚îÇ     ‚îÇ Permet :        ‚îÇ
‚îÇ - Upload blocs  ‚îÇ     ‚îÇ - Lire fichiers ‚îÇ
‚îÇ - Modifier meta ‚îÇ     ‚îÇ - √âcrire        ‚îÇ
‚îÇ - Supprimer     ‚îÇ     ‚îÇ   fichiers      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Vol du token seul    ‚Üí Acc√®s aux blocs CHIFFR√âS (inutiles)
Vol de la cl√© seule  ‚Üí Impossible d'acc√©der au serveur
Vol des deux         ‚Üí Compromission (mais n√©cessite acc√®s physique)
Hack du serveur      ‚Üí RIEN (Zero Knowledge)
Hack du storage OVH  ‚Üí RIEN (blocs chiffr√©s)
```

### 2.2 Chiffrement des blocs
```python
# Algorithme : AES-256-GCM (ou ChaCha20-Poly1305)
# D√©rivation : Argon2id depuis master password

from cryptography.hazmat.primitives.ciphers.aead import AESGCM
import os

CHUNK_SIZE = 4 * 1024 * 1024  # 4 MB

def derive_key(master_password: str, salt: bytes) -> bytes:
    """D√©rive une cl√© 256-bit depuis le mot de passe"""
    from argon2.low_level import hash_secret_raw, Type
    return hash_secret_raw(
        secret=master_password.encode(),
        salt=salt,
        time_cost=3,
        memory_cost=65536,
        parallelism=4,
        hash_len=32,
        type=Type.ID
    )

def encrypt_chunk(data: bytes, key: bytes) -> bytes:
    """Chiffre un bloc avec nonce unique"""
    nonce = os.urandom(12)  # 96 bits pour AES-GCM
    aesgcm = AESGCM(key)
    ciphertext = aesgcm.encrypt(nonce, data, None)
    return nonce + ciphertext  # Pr√©fixe le nonce

def decrypt_chunk(encrypted: bytes, key: bytes) -> bytes:
    """D√©chiffre un bloc"""
    nonce = encrypted[:12]
    ciphertext = encrypted[12:]
    aesgcm = AESGCM(key)
    return aesgcm.decrypt(nonce, ciphertext, None)
```

### 2.3 Stockage de la cl√© locale
```json
// ~/.syncagent/keyfile.json (chiffr√© par mot de passe OS ou master password)
{
  "salt": "base64...",
  "encrypted_master_key": "base64...",
  "key_id": "uuid",
  "created_at": "2025-01-01T00:00:00Z"
}
```

---

## 3. Serveur M√©tadonn√©es

### 3.1 Ce que le serveur stocke
```sql
-- Fichiers (m√©tadonn√©es uniquement)
CREATE TABLE files (
    id INTEGER PRIMARY KEY,
    path TEXT NOT NULL UNIQUE,       -- Chemin relatif UNIQUE (NON chiffr√© pour recherche)
    is_directory BOOLEAN DEFAULT FALSE,  -- TRUE pour dossiers vides
    current_version_id TEXT,         -- NULL pour dossiers vides
    created_at REAL,
    updated_at REAL,
    is_deleted BOOLEAN DEFAULT FALSE,
    deleted_at REAL,                 -- Timestamp suppression (pour corbeille 30j)
    deleted_by_machine_id TEXT       -- Machine ayant supprim√©
);

-- Versions (branches)
CREATE TABLE versions (
    id TEXT PRIMARY KEY,             -- UUID
    file_id INTEGER,
    machine_id TEXT,
    chunk_hashes TEXT,               -- JSON: ["hash1", "hash2", ...]
    size INTEGER,
    mtime REAL,
    created_at REAL,
    parent_version_id TEXT,          -- Pour l'historique
    FOREIGN KEY (file_id) REFERENCES files(id)
);

-- Conflits d√©tect√©s
CREATE TABLE conflicts (
    id INTEGER PRIMARY KEY,
    file_id INTEGER,
    detected_at REAL,
    branches TEXT,                   -- JSON: [{"machine": "laptop", "version_id": "..."}]
    resolved BOOLEAN DEFAULT FALSE,
    FOREIGN KEY (file_id) REFERENCES files(id)
);

-- Machines enregistr√©es
CREATE TABLE machines (
    machine_id TEXT PRIMARY KEY,
    name TEXT UNIQUE NOT NULL,
    os TEXT,
    token_hash TEXT NOT NULL,
    created_at REAL,
    last_seen REAL,
    is_active BOOLEAN DEFAULT TRUE
);

-- Invitations (tokens √† usage unique)
CREATE TABLE invitations (
    token_hash TEXT PRIMARY KEY,
    created_at REAL,
    expires_at REAL,              -- created_at + 24h
    used_by_machine_id TEXT,      -- NULL si pas encore utilis√©
    used_at REAL
);

-- Admin unique (un seul enregistrement possible)
CREATE TABLE admin (
    id INTEGER PRIMARY KEY CHECK (id = 1),
    username TEXT NOT NULL,
    password_hash TEXT NOT NULL,  -- Argon2id
    created_at REAL
);

-- Sessions admin (Web UI)
CREATE TABLE sessions (
    token_hash TEXT PRIMARY KEY,
    created_at REAL,
    expires_at REAL,              -- created_at + 24h (configurable)
    user_agent TEXT,
    ip_address TEXT
);
-- Nettoyage automatique des sessions expir√©es via background job

-- Mapping blocs ‚Üí storage (sans d√©duplication inter-fichiers v1)
CREATE TABLE chunks (
    hash TEXT PRIMARY KEY,
    file_id INTEGER NOT NULL,        -- Fichier propri√©taire (pas de d√©dup)
    storage_path TEXT,               -- Chemin dans OVH
    size INTEGER,
    uploaded_at REAL,
    FOREIGN KEY (file_id) REFERENCES files(id)
);
-- Note v1 : Chaque fichier poss√®de ses propres chunks.
-- Suppression directe des chunks √† la purge de corbeille.
-- D√©duplication inter-fichiers pr√©vue en v2 (ref_count, GC avec grace period).

-- Configuration serveur
CREATE TABLE config (
    key TEXT PRIMARY KEY,
    value TEXT
);
-- Valeurs par d√©faut:
-- trash_retention_days: 30
```

### 3.2 API HTTPS

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| `POST` | `/api/auth/register` | Enregistre une machine (token retourn√© √† la cr√©ation) |
| `GET` | `/api/files` | Liste les fichiers (m√©tadonn√©es) |
| `GET` | `/api/files/{id}/versions` | Versions d'un fichier |
| `POST` | `/api/files` | Cr√©e/modifie un fichier (metadata) |
| `DELETE` | `/api/files/{id}` | Supprime (tombstone) |
| `GET` | `/api/chunks/{hash}` | T√©l√©charge un bloc chiffr√© |
| `POST` | `/api/chunks` | Upload un bloc chiffr√© |
| `HEAD` | `/api/chunks/{hash}` | V√©rifie si bloc existe |
| `GET` | `/api/conflicts` | Liste les conflits |
| `POST` | `/api/conflicts/{id}/resolve` | R√©sout un conflit |
| `GET` | `/api/status` | √âtat des machines |
| `GET` | `/api/changes?since=<ts>` | Changements depuis timestamp (catch-up) |
| `POST` | `/api/auth/check-name` | V√©rifie disponibilit√© nom machine |
| `GET` | `/api/trash` | Liste fichiers supprim√©s (corbeille) |
| `POST` | `/api/trash/{id}/restore` | Restaure un fichier |
| `DELETE` | `/api/trash/{id}` | Supprime d√©finitivement |
| `GET` | `/api/invitations` | Liste invitations (admin) |
| `POST` | `/api/invitations` | Cr√©e une invitation (admin) |
| `DELETE` | `/api/invitations/{id}` | R√©voque une invitation (admin) |

### 3.3 Setup Wizard (premi√®re visite Web UI)

√Ä la premi√®re connexion sur la Web UI, si aucun admin n'existe, l'utilisateur est redirig√© vers un √©cran de setup :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SyncAgent - Setup                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Bienvenue ! Cr√©ez votre compte administrateur.                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Nom d'utilisateur                                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îÇ admin                                               ‚îÇ ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Mot de passe                                            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢                                        ‚îÇ ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Confirmer le mot de passe                               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îÇ ‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢                                        ‚îÇ ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ                              [Cr√©er le compte]                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
from fastapi import FastAPI, Request
from fastapi.responses import RedirectResponse

def needs_setup(db) -> bool:
    """V√©rifie si le setup initial est n√©cessaire"""
    return db.execute("SELECT 1 FROM admin WHERE id = 1").fetchone() is None

@app.middleware("http")
async def setup_redirect(request: Request, call_next):
    """Redirige vers /setup si pas d'admin configur√©"""
    if needs_setup(db):
        # Autoriser uniquement /setup et ses assets
        if not request.url.path.startswith(("/setup", "/static")):
            return RedirectResponse(url="/setup")
    else:
        # Setup d√©j√† fait, bloquer l'acc√®s √† /setup
        if request.url.path.startswith("/setup"):
            return RedirectResponse(url="/")
    return await call_next(request)

@app.get("/setup")
def setup_page():
    """Page de cr√©ation du compte admin"""
    if not needs_setup(db):
        return RedirectResponse(url="/")
    return templates.TemplateResponse("setup.html", {})

@app.post("/setup")
def create_admin(username: str, password: str, password_confirm: str):
    """Cr√©e le compte admin"""
    if not needs_setup(db):
        return RedirectResponse(url="/")

    if password != password_confirm:
        return {"error": "Les mots de passe ne correspondent pas"}

    if len(password) < 14:
        return {"error": "Mot de passe trop court (min 14 caract√®res)"}

    ph = PasswordHasher()
    db.execute("""
        INSERT INTO admin (id, username, password_hash, created_at)
        VALUES (1, ?, ?, ?)
    """, (username, ph.hash(password), time.time()))
    db.commit()

    return RedirectResponse(url="/login")
```

### 3.4 Web UI (FastAPI + Jinja2 + HTMX)
- **Affiche uniquement les m√©tadonn√©es** (noms, tailles, dates, conflits)
- **Ne peut PAS afficher le contenu** des fichiers (Zero Knowledge)
- **Lien vers client local** via `syncfile://` pour ouvrir les fichiers

```html
<!-- Le front ne voit que √ßa -->
<tr>
  <td>
    <a href="syncfile://open?path=/docs/rapport.pdf">
      rapport.pdf
    </a>
  </td>
  <td>2.4 MB</td>
  <td>2025-01-15 14:30</td>
  <td>laptop</td>
</tr>
```

### 3.5 Workflow initial (Setup ‚Üí Premi√®re machine)

```
1. SERVEUR
   - D√©marrage serveur (premier lancement)
   - DB vide, pas d'admin

2. ADMIN (Web UI)
   - Acc√®s https://sync.mondomaine.com
   - Redirection auto vers /setup (pas d'admin)
   - Cr√©ation compte admin (username + password 14+ chars)
   - Connexion Web UI avec session cookie

3. INVITATION (Web UI)
   - Admin g√©n√®re un token d'invitation
   - Token affich√© : INV-xxxxxxxxxxxx (expire 24h)
   - Admin copie le token

4. PREMI√àRE MACHINE (CLI)
   - syncagent init
   - Saisie URL serveur, token invitation, nom machine
   - G√©n√©ration cl√© E2EE (premi√®re machine)
   - POST /api/auth/register ‚Üí token machine
   - Export cl√© : syncagent export-key > ma-cle.key

5. MACHINES SUIVANTES (CLI)
   - Admin g√©n√®re nouvelle invitation (Web UI)
   - syncagent init --import-key ma-cle.key
   - Saisie URL, invitation, nom
   - Import cl√© E2EE (m√™me cl√© que premi√®re machine)
   - POST /api/auth/register ‚Üí nouveau token machine
```

### 3.6 Background Jobs (serveur)

Le serveur ex√©cute des t√¢ches de maintenance p√©riodiques :

```python
import asyncio
from datetime import datetime, timedelta

async def background_jobs():
    """T√¢ches de maintenance ex√©cut√©es en arri√®re-plan"""
    while True:
        await asyncio.gather(
            purge_expired_trash(),
            cleanup_expired_sessions(),
            cleanup_expired_invitations(),
        )
        await asyncio.sleep(3600)  # Toutes les heures

async def purge_expired_trash():
    """Purge les fichiers en corbeille expir√©s et leurs chunks"""
    retention = get_config('trash_retention_days', 30)
    cutoff = time.time() - (retention * 86400)

    expired = db.execute("""
        SELECT id FROM files
        WHERE is_deleted = TRUE AND deleted_at < ?
    """, (cutoff,)).fetchall()

    for file in expired:
        # Supprimer les chunks associ√©s
        await storage.delete_by_file(file['id'])
        # Supprimer le fichier de la DB
        db.execute("DELETE FROM files WHERE id = ?", (file['id'],))

    db.commit()
    logger.info(f"Purged {len(expired)} expired files from trash")

async def cleanup_expired_sessions():
    """Nettoie les sessions admin expir√©es"""
    db.execute("DELETE FROM sessions WHERE expires_at < ?", (time.time(),))
    db.commit()

async def cleanup_expired_invitations():
    """Nettoie les invitations expir√©es non utilis√©es"""
    db.execute("""
        DELETE FROM invitations
        WHERE expires_at < ? AND used_by_machine_id IS NULL
    """, (time.time(),))
    db.commit()
```

### 3.7 D√©tection machine offline (WebSocket)

```python
# Configuration
WS_HEARTBEAT_INTERVAL = 30  # Client envoie ping toutes les 30s (configurable)
WS_TIMEOUT = 90             # Serveur ferme si pas de ping depuis 90s (3x interval)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # ... authentification ...

    await websocket.accept()
    active_connections[machine.machine_id] = websocket

    # Mettre √† jour last_seen et notifier les autres
    update_machine_last_seen(machine.machine_id)
    await broadcast_to_others(machine.machine_id, {
        "type": "machine_online",
        "machine_id": machine.machine_id,
        "name": machine.name
    })

    try:
        while True:
            # Timeout si pas de message depuis WS_TIMEOUT secondes
            data = await asyncio.wait_for(
                websocket.receive_json(),
                timeout=WS_TIMEOUT
            )
            if data.get("type") == "ping":
                update_machine_last_seen(machine.machine_id)
                await websocket.send_json({"type": "pong"})
    except (WebSocketDisconnect, asyncio.TimeoutError):
        del active_connections[machine.machine_id]
        await broadcast_to_others(machine.machine_id, {
            "type": "machine_offline",
            "machine_id": machine.machine_id,
            "name": machine.name
        })
```

### 3.8 Gestion des erreurs chunks (404)

```python
# Client : gestion du 404 lors du download
async def download_chunk_safe(chunk_hash: str) -> bytes | None:
    """T√©l√©charge un chunk avec gestion du 404"""
    try:
        response = await httpx.get(f"{server_url}/api/chunks/{chunk_hash}")
        if response.status_code == 404:
            # Chunk supprim√© (fichier purg√© de corbeille pendant le download)
            logger.warning(f"Chunk {chunk_hash} not found (deleted)")
            return None
        response.raise_for_status()
        return response.content
    except httpx.HTTPStatusError as e:
        logger.error(f"Failed to download chunk {chunk_hash}: {e}")
        raise

async def download_file_safe(file_id: str, version_id: str, local_path: str) -> bool:
    """Download avec retry si 404 sur chunk"""
    metadata = await api.get_version(file_id, version_id)

    # Si le fichier a √©t√© purg√© entre-temps, ses chunks n'existent plus
    if metadata.get('is_deleted') and metadata.get('deleted_at'):
        if time.time() - metadata['deleted_at'] > (30 * 86400):  # > 30 jours
            logger.warning(f"File {file_id} was purged, skipping download")
            return False

    with open(local_path, 'wb') as f:
        for chunk_hash in metadata['chunk_hashes']:
            chunk_data = await download_chunk_safe(chunk_hash)
            if chunk_data is None:
                # Chunk manquant ‚Üí fichier incomplet
                logger.error(f"Missing chunk {chunk_hash}, aborting download")
                return False
            decrypted = decrypt_chunk(chunk_data, e2ee_key)
            f.write(decrypted)

    return True
```

---

## 4. Client Local

### 4.1 Enregistrement d'un nouveau client

#### Processus d'initialisation
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    syncagent init                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  1. Demande l'URL du serveur                                    ‚îÇ
‚îÇ     > URL du serveur: https://sync.mondomaine.com               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  2. Demande le token d'invitation (g√©n√©r√© via Web UI)           ‚îÇ
‚îÇ     > Token d'invitation: INV-a8f3b2c9d4e5f6a7                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  3. Demande le nom de la machine                                ‚îÇ
‚îÇ     > Nom de cette machine: laptop-julien                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  4. Demande le dossier local √† synchroniser                     ‚îÇ
‚îÇ     > Dossier √† synchroniser: ~/Sync                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  5. Premi√®re machine ? ‚Üí G√©n√®re la cl√© E2EE                     ‚îÇ
‚îÇ     Machine existante ? ‚Üí Importe la cl√© E2EE                   ‚îÇ
‚îÇ     > Mot de passe ma√Ætre: ********                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  6. Enregistre la machine sur le serveur                        ‚îÇ
‚îÇ     POST /api/auth/register                                     ‚îÇ
‚îÇ     {                                                           ‚îÇ
‚îÇ       "invite_token": "INV-a8f3b2c9d4e5f6a7",                   ‚îÇ
‚îÇ       "name": "laptop-julien",                                  ‚îÇ
‚îÇ       "os": "windows"                                           ‚îÇ
‚îÇ     }                                                           ‚îÇ
‚îÇ     ‚Üí 201 Created {"machine_id": "uuid...", "token": "..."}     ‚îÇ
‚îÇ     ‚Üí Token d'invitation consomm√© (usage unique)                ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  7. Sauvegarde la config locale                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### G√©n√©ration d'invitation (Web UI)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WEB UI - Machines                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  Machines connect√©es:                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ üü¢ laptop-julien    Windows   Derni√®re sync: il y a 2m  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ üü¢ desktop-bureau   Linux     Derni√®re sync: il y a 5m  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  [+ Inviter une machine]                                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Invitations en attente:                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ INV-a8f3...  Cr√©√©e il y a 2h   Expire dans 22h  [üóëÔ∏è]   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ INV-b7c2...  Cr√©√©e il y a 1j   EXPIR√â           [üóëÔ∏è]   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Clic sur [+ Inviter une machine]:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                 ‚îÇ
‚îÇ  Token d'invitation g√©n√©r√© :                                    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  INV-a8f3b2c9d4e5f6a7                        [Copier]   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚ö†Ô∏è Ce token expire dans 24h et ne peut √™tre utilis√© qu'une    ‚îÇ
‚îÇ     seule fois.                                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Commande √† ex√©cuter sur la nouvelle machine :                  ‚îÇ
‚îÇ  $ syncagent init                                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ                                              [Fermer]           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Contraintes sur le nom de machine
- **Unique** sur le serveur (v√©rifi√© √† l'enregistrement)
- **Format:** lettres, chiffres, tirets, underscores
- **Longueur:** 3-32 caract√®res
- **Pas de caract√®res sp√©ciaux** (sera utilis√© dans les noms de fichiers conflits)

```python
import re

def validate_machine_name(name: str) -> bool:
    """Valide le format du nom de machine"""
    pattern = r'^[a-zA-Z0-9_-]{3,32}$'
    return bool(re.match(pattern, name))

# Exemples valides:
# - laptop-julien
# - desktop_bureau
# - macbook-pro-2024
# - PC01

# Exemples invalides:
# - "mon pc" (espaces)
# - "laptop@home" (caract√®re sp√©cial)
# - "ab" (trop court)
```

#### API d'enregistrement (serveur)
```python
@app.post("/api/auth/check-name")
def check_name():
    """V√©rifie si un nom de machine est disponible"""
    name = request.json['name']

    if not validate_machine_name(name):
        return {"error": "Invalid name format"}, 400

    exists = db.execute(
        "SELECT 1 FROM machines WHERE name = ?", (name,)
    ).fetchone()

    if exists:
        return {"error": "Name already taken"}, 409

    return {"available": True}, 200


@app.post("/api/auth/register")
def register_machine():
    """Enregistre une nouvelle machine avec validation du token d'invitation"""
    data = request.json
    name = data['name']
    os_type = data['os']
    invite_token = data.get('invite_token')

    # 1. Valider le token d'invitation
    if not invite_token:
        return {"error": "Invitation token required"}, 401

    invite_hash = hashlib.sha256(invite_token.encode()).hexdigest()
    invitation = db.execute("""
        SELECT token_hash, expires_at, used_by_machine_id
        FROM invitations
        WHERE token_hash = ?
    """, (invite_hash,)).fetchone()

    if not invitation:
        return {"error": "Invalid invitation token"}, 401

    if invitation['used_by_machine_id']:
        return {"error": "Invitation token already used"}, 401

    if invitation['expires_at'] < time.time():
        return {"error": "Invitation token expired"}, 401

    # 2. Valider le nom de machine
    if not validate_machine_name(name):
        return {"error": "Invalid name format"}, 400

    exists = db.execute(
        "SELECT 1 FROM machines WHERE name = ?", (name,)
    ).fetchone()
    if exists:
        return {"error": "Name already taken"}, 409

    # 3. Cr√©er la machine
    machine_id = str(uuid.uuid4())
    token = secrets.token_urlsafe(32)
    token_hash = hashlib.sha256(token.encode()).hexdigest()

    db.execute("""
        INSERT INTO machines (machine_id, name, os, token_hash, created_at, last_seen)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (machine_id, name, os_type, token_hash, time.time(), time.time()))

    # 4. Marquer l'invitation comme utilis√©e
    db.execute("""
        UPDATE invitations
        SET used_by_machine_id = ?, used_at = ?
        WHERE token_hash = ?
    """, (machine_id, time.time(), invite_hash))

    db.commit()

    return {
        "machine_id": machine_id,
        "token": token  # Renvoy√© une seule fois !
    }, 201
```

#### Sch√©ma DB machines (mis √† jour)
```sql
CREATE TABLE machines (
    machine_id TEXT PRIMARY KEY,
    name TEXT UNIQUE NOT NULL,       -- Nom unique choisi par l'utilisateur
    os TEXT,                         -- windows, darwin, linux
    token_hash TEXT NOT NULL,        -- Hash du token (jamais le token en clair)
    created_at REAL,
    last_seen REAL,
    is_active BOOLEAN DEFAULT TRUE
);
```

### 4.2 Configuration locale
```json
// ~/.syncagent/config.json
{
  "machine_name": "laptop-julien",
  "server_url": "https://sync.mondomaine.com",
  "auth_token": "token-secret-stock√©-localement",
  "local_path": "/home/user/Sync",
  "cdc": {
    "avg_size": 4194304,   // 4 MB moyenne
    "min_size": 1048576,   // 1 MB minimum
    "max_size": 8388608    // 8 MB maximum
  },
  "ignore_patterns": [".git", "*.tmp", ".DS_Store", "Thumbs.db"]
}
```

**Ignore patterns** : Syntaxe gitignore-like (glob patterns)
- `*.tmp` ‚Üí tous les fichiers .tmp
- `.git` ‚Üí dossier .git
- `build/` ‚Üí dossier build et son contenu
- `!important.tmp` ‚Üí exception (ne pas ignorer)

Un fichier `.syncignore` √† la racine du dossier sync peut √©galement √™tre utilis√©.
- **Note :** `.syncignore` est lui-m√™me synchronis√© entre machines (comme `.gitignore`)
- Si une machine modifie `.syncignore`, les autres machines re√ßoivent la mise √† jour

### 4.2bis SQLite local (√©tat client)
```sql
-- ~/.syncagent/db.sqlite

-- Fichiers locaux (cache des m√©tadonn√©es)
CREATE TABLE local_files (
    id INTEGER PRIMARY KEY,
    path TEXT NOT NULL UNIQUE,       -- Chemin relatif dans le dossier sync
    server_file_id INTEGER,          -- ID c√¥t√© serveur (NULL si nouveau local)
    server_version_id TEXT,          -- Version actuelle sur le serveur
    local_mtime REAL,                -- Modification time local
    local_size INTEGER,
    local_hash TEXT,                 -- Hash du fichier local (pour d√©tecter changements)
    chunk_hashes TEXT,               -- JSON: ["hash1", "hash2", ...] (cache local)
    status TEXT DEFAULT 'synced',    -- synced, modified, pending_upload, conflict
    last_synced_at REAL
);

-- Uploads en attente (modifications locales non encore pouss√©es)
CREATE TABLE pending_uploads (
    id INTEGER PRIMARY KEY,
    path TEXT NOT NULL,
    detected_at REAL,
    attempts INTEGER DEFAULT 0,
    last_attempt_at REAL,
    error TEXT                       -- Derni√®re erreur si √©chec
);

-- Chunks localement cach√©s (optionnel, pour √©viter re-t√©l√©chargement)
CREATE TABLE local_chunks (
    hash TEXT PRIMARY KEY,
    local_path TEXT,                 -- Chemin cache local
    size INTEGER,
    last_accessed_at REAL
);

-- √âtat global de sync
CREATE TABLE sync_state (
    key TEXT PRIMARY KEY,
    value TEXT
);
-- Cl√©s:
-- last_sync_at: timestamp derni√®re sync r√©ussie
-- last_server_version: version serveur connue
-- daemon_started_at: timestamp d√©marrage daemon
```

**Usage :**
```python
def detect_local_changes():
    """Compare l'√©tat local avec la DB pour d√©tecter les modifs"""
    for path in scan_sync_folder():
        file_stat = os.stat(path)
        db_entry = db.get_local_file(path)

        if not db_entry:
            # Nouveau fichier
            mark_pending_upload(path)
        elif file_stat.st_mtime > db_entry.local_mtime:
            # Fichier modifi√©
            mark_pending_upload(path)

def mark_synced(path, server_file_id, server_version_id):
    """Marque un fichier comme synchronis√©"""
    db.execute("""
        UPDATE local_files
        SET status = 'synced',
            server_file_id = ?,
            server_version_id = ?,
            last_synced_at = ?
        WHERE path = ?
    """, (server_file_id, server_version_id, time.time(), path))
```

### 4.3 Partage de la cl√© E2EE entre machines

#### Premi√®re machine (g√©n√©ration)
```bash
$ syncagent init
> Nom de cette machine: laptop-julien
> URL du serveur: https://sync.mondomaine.com
> Dossier √† synchroniser: ~/Sync
> Mot de passe ma√Ætre (pour chiffrer la cl√©): ********
> Confirmer le mot de passe: ********

‚úì Cl√© E2EE g√©n√©r√©e
‚úì Machine enregistr√©e sur le serveur
‚úì Configuration sauvegard√©e

Pour ajouter une autre machine, exportez la cl√©:
  syncagent export-key > ma-cle.key
```

#### Machines suivantes (import)
```bash
$ syncagent init --import-key ma-cle.key
> Nom de cette machine: desktop-bureau
> URL du serveur: https://sync.mondomaine.com
> Dossier √† synchroniser: ~/Sync
> Mot de passe ma√Ætre: ********

‚úì Cl√© E2EE import√©e
‚úì Machine enregistr√©e sur le serveur
‚úì Configuration sauvegard√©e
```

#### Format du fichier de cl√© export√©
```json
// ma-cle.key (fichier √† transf√©rer de mani√®re s√©curis√©e)
{
  "version": 1,
  "salt": "base64...",
  "encrypted_master_key": "base64...",
  "key_id": "uuid",
  "created_at": "2025-01-01T00:00:00Z",
  "checksum": "sha256..."  // Pour v√©rifier l'int√©grit√©
}
```

‚ö†Ô∏è **S√©curit√©:** Le fichier `.key` doit √™tre transf√©r√© de mani√®re s√©curis√©e (USB, AirDrop, partage direct). Ne jamais l'envoyer par email ou messagerie non chiffr√©e.

### 4.4 CLI
```bash
syncagent init                    # Configure + g√©n√®re cl√© E2EE
syncagent unlock                  # D√©verrouille la cl√© (mot de passe)
syncagent lock                    # Verrouille la cl√© (efface de la m√©moire)
syncagent watch                   # D√©marre le daemon
syncagent sync                    # Force une sync
syncagent status                  # √âtat local
syncagent conflicts               # Liste les conflits
syncagent register-protocol       # Enregistre syncfile://
syncagent export-key              # Exporte la cl√© (pour autre machine)
syncagent import-key <file>       # Importe une cl√©
syncagent change-password         # Change le master password
```

### 4.5 Workflow de sync (upload avec CDC)
```python
def sync_file(file_path: str):
    """Sync un fichier avec Content-Defined Chunking"""

    # 1. D√©couper avec CDC (fronti√®res bas√©es sur le contenu)
    chunks = content_defined_chunking(file_path)

    # 2. Pour chaque chunk
    chunk_hashes = []
    for offset, length, chunk_data in chunks:
        # Hash AVANT chiffrement (pour identifier le chunk)
        chunk_hash = hashlib.sha256(chunk_data).hexdigest()
        chunk_hashes.append(chunk_hash)

        # Upload le chunk chiffr√©
        encrypted = encrypt_chunk(chunk_data, e2ee_key)
        api.upload_chunk(chunk_hash, encrypted, file_id)

    # 3. Mettre √† jour les m√©tadonn√©es
    api.update_file_metadata(file_path, chunk_hashes, machine_id)
```

### 4.6 Workflow de sync (download)
```python
def download_file(file_id: str, version_id: str, local_path: str):
    # 1. R√©cup√©rer les m√©tadonn√©es
    metadata = api.get_version(file_id, version_id)
    chunk_hashes = metadata['chunk_hashes']

    # 2. T√©l√©charger et d√©chiffrer chaque bloc
    with open(local_path, 'wb') as f:
        for chunk_hash in chunk_hashes:
            encrypted = api.download_chunk(chunk_hash)
            decrypted = decrypt_chunk(encrypted, e2ee_key)
            f.write(decrypted)
```

---

## 5. Gestion des Conflits

fileA ()
fileB ()

if fileA


### 5.1 Strat√©gie : Duplication automatique
Quand deux machines modifient le m√™me fichier depuis la m√™me version de base :
```
document.txt                        ‚Üê Version principale (ou locale)
document (conflit - laptop).txt     ‚Üê Version du laptop
document (conflit - desktop).txt    ‚Üê Version du desktop
```

### 5.1bis Cas particulier : Delete vs Modify
Si machine A supprime un fichier et machine B le modifie (en parall√®le) :
- **La modification gagne** ‚Üí le fichier n'est PAS supprim√©
- Cr√©er un fichier conflit : `document (conflit - machineB).ext`
- Marquer comme conflit √† r√©soudre par l'utilisateur
- L'utilisateur peut ensuite :
  - Garder le fichier modifi√©
  - Supprimer d√©finitivement
  - Restaurer la version avant suppression

### 5.2 D√©tection (c√¥t√© serveur)
```python
def handle_file_update(file_id, new_version, machine_id, parent_version_id):
    current = db.get_current_version(file_id)

    if parent_version_id == current.id:
        # Mise √† jour lin√©aire ‚Üí OK
        db.set_current_version(file_id, new_version)
    else:
        # Conflit ! La version parente n'est pas la version actuelle
        db.create_conflict_branch(file_id, new_version, machine_id)
        db.mark_file_conflicted(file_id)
```

### 5.3 Reconstruction (c√¥t√© client)
```python
def handle_conflicts():
    conflicts = api.get_conflicts()

    for conflict in conflicts:
        file_path = conflict['path']
        branches = conflict['branches']

        for branch in branches:
            machine_name = branch['machine']
            version_id = branch['version_id']

            # Cr√©er le fichier conflit
            conflict_path = f"{file_path} (conflit - {machine_name})"
            download_file(conflict['file_id'], version_id, conflict_path)
```

### 5.4 R√©solution
L'utilisateur choisit manuellement :
1. Garde une version ‚Üí supprime les autres branches
2. Renomme une version comme principale
3. Fusionne manuellement (copier-coller)

Via l'UI web ou le client local.

---

## 6. Block Storage (Abstrait)

### 6.1 Interface abstraite
```python
from abc import ABC, abstractmethod
from typing import Optional

class ChunkStorage(ABC):
    """Interface pour le stockage des blocs chiffr√©s"""

    @abstractmethod
    def put(self, chunk_hash: str, data: bytes, file_id: int) -> None:
        """Upload un bloc chiffr√© li√© √† un fichier"""
        pass

    @abstractmethod
    def get(self, chunk_hash: str) -> bytes:
        """T√©l√©charge un bloc chiffr√©"""
        pass

    @abstractmethod
    def exists(self, chunk_hash: str) -> bool:
        """V√©rifie si un bloc existe"""
        pass

    @abstractmethod
    def delete(self, chunk_hash: str) -> None:
        """Supprime un bloc"""
        pass

    @abstractmethod
    def delete_by_file(self, file_id: int) -> int:
        """Supprime tous les blocs d'un fichier. Retourne le nombre de blocs supprim√©s."""
        pass
```

### 6.2 Impl√©mentation Local FS (dev/test)
```python
import os
from pathlib import Path

class LocalFSStorage(ChunkStorage):
    """Stockage local pour d√©veloppement et tests"""

    def __init__(self, base_path: str, db):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        self.db = db  # R√©f√©rence √† la DB pour delete_by_file

    def _chunk_path(self, chunk_hash: str) -> Path:
        # Sous-dossiers par pr√©fixe pour √©viter trop de fichiers par dossier
        prefix = chunk_hash[:2]
        return self.base_path / prefix / f"{chunk_hash}.enc"

    def put(self, chunk_hash: str, data: bytes, file_id: int) -> None:
        path = self._chunk_path(chunk_hash)
        path.parent.mkdir(exist_ok=True)
        path.write_bytes(data)
        # Note: l'enregistrement dans la table chunks est fait par l'appelant (API)

    def get(self, chunk_hash: str) -> bytes:
        return self._chunk_path(chunk_hash).read_bytes()

    def exists(self, chunk_hash: str) -> bool:
        return self._chunk_path(chunk_hash).exists()

    def delete(self, chunk_hash: str) -> None:
        path = self._chunk_path(chunk_hash)
        if path.exists():
            path.unlink()

    def delete_by_file(self, file_id: int) -> int:
        """Supprime tous les chunks d'un fichier. Retourne le nombre supprim√©."""
        chunks = self.db.execute(
            "SELECT hash FROM chunks WHERE file_id = ?", (file_id,)
        ).fetchall()

        deleted = 0
        for chunk in chunks:
            self.delete(chunk['hash'])
            deleted += 1

        self.db.execute("DELETE FROM chunks WHERE file_id = ?", (file_id,))
        return deleted
```

### 6.3 Impl√©mentation S3-compatible (OVH, AWS, MinIO...)
```python
import boto3
from botocore.exceptions import ClientError

class S3Storage(ChunkStorage):
    """Stockage S3-compatible pour production"""

    def __init__(self, endpoint_url: str, access_key: str, secret_key: str, bucket: str, db):
        self.bucket = bucket
        self.db = db  # R√©f√©rence √† la DB pour delete_by_file
        self.client = boto3.client(
            's3',
            endpoint_url=endpoint_url,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key
        )

    def _key(self, chunk_hash: str) -> str:
        # Pr√©fixe pour distribution dans le bucket
        return f"chunks/{chunk_hash[:2]}/{chunk_hash}.enc"

    def put(self, chunk_hash: str, data: bytes, file_id: int) -> None:
        self.client.put_object(
            Bucket=self.bucket,
            Key=self._key(chunk_hash),
            Body=data
        )
        # Note: l'enregistrement dans la table chunks est fait par l'appelant (API)

    def get(self, chunk_hash: str) -> bytes:
        response = self.client.get_object(
            Bucket=self.bucket,
            Key=self._key(chunk_hash)
        )
        return response['Body'].read()

    def exists(self, chunk_hash: str) -> bool:
        try:
            self.client.head_object(Bucket=self.bucket, Key=self._key(chunk_hash))
            return True
        except ClientError:
            return False

    def delete(self, chunk_hash: str) -> None:
        self.client.delete_object(Bucket=self.bucket, Key=self._key(chunk_hash))

    def delete_by_file(self, file_id: int) -> int:
        """Supprime tous les chunks d'un fichier. Retourne le nombre supprim√©."""
        chunks = self.db.execute(
            "SELECT hash FROM chunks WHERE file_id = ?", (file_id,)
        ).fetchall()

        deleted = 0
        for chunk in chunks:
            self.delete(chunk['hash'])
            deleted += 1

        self.db.execute("DELETE FROM chunks WHERE file_id = ?", (file_id,))
        return deleted
```

### 6.4 Configuration serveur
```json
// config.json serveur
{
  "storage": {
    "type": "local",  // "local" ou "s3"

    // Si type = "local"
    "local_path": "/srv/sync/chunks",

    // Si type = "s3"
    "s3_endpoint": "https://s3.gra.cloud.ovh.net",
    "s3_access_key": "...",
    "s3_secret_key": "...",
    "s3_bucket": "sync-chunks"
  }
}
```

### 6.5 Factory
```python
def create_storage(config: dict) -> ChunkStorage:
    if config['type'] == 'local':
        return LocalFSStorage(config['local_path'])
    elif config['type'] == 's3':
        return S3Storage(
            endpoint_url=config['s3_endpoint'],
            access_key=config['s3_access_key'],
            secret_key=config['s3_secret_key'],
            bucket=config['s3_bucket']
        )
    else:
        raise ValueError(f"Unknown storage type: {config['type']}")
```

### 6.6 Gestion des chunks (v1 - sans d√©duplication)

**Version 1 (actuelle) :**
- Chaque fichier poss√®de ses propres chunks exclusivement
- Pas de partage de chunks entre fichiers diff√©rents
- Suppression simple : quand un fichier est purg√© de la corbeille, ses chunks sont supprim√©s imm√©diatement
- Avantage : architecture simple, pas de GC complexe, pas de risque de corruption

**Version 2 (pr√©vue ult√©rieurement) - D√©duplication inter-fichiers :**
- Le hash serait calcul√© sur le contenu EN CLAIR (avant chiffrement)
- Si deux fichiers ont des blocs identiques ‚Üí m√™me hash ‚Üí un seul stockage
- Le serveur compterait les r√©f√©rences (`ref_count`) pour garbage collection
- GC avec grace period pour √©viter les race conditions

### 6.7 Content-Defined Chunking (CDC)

#### Pourquoi CDC plut√¥t que Fixed-size chunking ?

**Fixed-size (4 MB fixes) :**
```
Fichier original:  [chunk0][chunk1][chunk2][chunk3][chunk4]
Ins√©rer 1 octet:   [XXXXX0][XXXXX1][XXXXX2][XXXXX3][XXXXX4]  ‚Üê TOUS d√©calent
‚Üí 5 chunks √† re-uploader
```

**CDC (Content-Defined) :**
```
Fichier original:  [chunk0][chunk1][chunk2][chunk3][chunk4]
Ins√©rer 1 octet:   [chunkA][chunk1][chunk2][chunk3][chunk4]  ‚Üê Seul le 1er change
‚Üí 1 chunk √† re-uploader
```

#### Algorithme : FastCDC (recommand√©)
FastCDC est une impl√©mentation optimis√©e du Content-Defined Chunking.

```python
# Param√®tres CDC
CDC_AVG_SIZE = 4 * 1024 * 1024   # 4 MB moyenne
CDC_MIN_SIZE = 1 * 1024 * 1024   # 1 MB minimum
CDC_MAX_SIZE = 8 * 1024 * 1024   # 8 MB maximum

# Utiliser la lib fastcdc (pip install fastcdc)
from fastcdc import fastcdc
from typing import Iterator

def content_defined_chunking_stream(file_path: str) -> Iterator[tuple[int, int, bytes]]:
    """
    D√©coupe un fichier en chunks bas√©s sur le contenu (STREAMING).
    Utilise un g√©n√©rateur pour ne jamais charger plus d'un chunk en m√©moire.
    Retourne un it√©rateur de (offset, length, data).
    """
    # fastcdc supporte les fichiers directement (streaming natif)
    with open(file_path, 'rb') as f:
        for chunk in fastcdc(f, CDC_MIN_SIZE, CDC_AVG_SIZE, CDC_MAX_SIZE):
            # Lire uniquement ce chunk (max 8 MB en RAM)
            f.seek(chunk.offset)
            chunk_data = f.read(chunk.length)
            yield (chunk.offset, chunk.length, chunk_data)

# Note : La lib fastcdc accepte un file object ou bytes.
# En passant un file object, elle lit en streaming.
```

#### Alternative : Rolling hash maison (Rabin fingerprint)
```python
import hashlib

# Constantes pour Rabin fingerprint
PRIME = 31
MODULUS = 2**32
MASK = (1 << 20) - 1  # D√©termine la taille moyenne (~1 MB avec ce mask)

def rolling_hash_chunking(data: bytes) -> list[bytes]:
    """
    Impl√©mentation simple de CDC avec rolling hash.
    Les fronti√®res sont d√©finies quand le hash "matche" un pattern.
    """
    chunks = []
    start = 0
    window_size = 48  # Fen√™tre glissante

    hash_value = 0

    for i in range(len(data)):
        # Ajouter le nouveau byte au hash
        hash_value = (hash_value * PRIME + data[i]) % MODULUS

        # V√©rifier si on a trouv√© une fronti√®re
        if i - start >= CDC_MIN_SIZE:
            if (hash_value & MASK) == MASK or i - start >= CDC_MAX_SIZE:
                chunks.append(data[start:i])
                start = i
                hash_value = 0

    # Dernier chunk
    if start < len(data):
        chunks.append(data[start:])

    return chunks
```

#### Workflow de sync avec CDC
```python
def sync_file_cdc(file_path: str, file_id: int):
    """Sync un fichier avec Content-Defined Chunking"""

    # 1. D√©couper avec CDC
    chunks = content_defined_chunking(file_path)

    # 2. Pour chaque chunk
    chunk_hashes = []
    for offset, length, chunk_data in chunks:
        # Hash pour identifier le chunk
        chunk_hash = hashlib.sha256(chunk_data).hexdigest()
        chunk_hashes.append(chunk_hash)

        # Upload le chunk chiffr√© (li√© √† ce fichier)
        encrypted = encrypt_chunk(chunk_data, e2ee_key)
        api.upload_chunk(chunk_hash, encrypted, file_id)

    # 3. Mettre √† jour les m√©tadonn√©es
    api.update_file_metadata(file_path, chunk_hashes, machine_id)
```

#### Avantages CDC
| Sc√©nario | Fixed-size | CDC |
|----------|-----------|-----|
| Modification au milieu | 1 chunk | 1 chunk |
| Insertion au d√©but | **N chunks** | 1-2 chunks |
| Suppression d'une partie | **N chunks** | 1-2 chunks |
| Delta sync m√™me fichier | Efficace | **Tr√®s efficace** |

---

## 7. Protocol Handler

### 7.1 Format
```
syncfile://open?path=<relative_path>
syncfile://reveal?path=<relative_path>
```

### 7.2 S√©curit√©
- V√©rifie que le path est dans le dossier sync
- N'ex√©cute jamais de commandes arbitraires

### 7.3 Enregistrement par OS

#### Windows (Registry)
```python
import winreg
import sys

def register_protocol_windows():
    """Enregistre syncfile:// dans le registre Windows"""
    exe_path = sys.executable  # ou chemin vers syncagent.exe

    # HKEY_CURRENT_USER\Software\Classes\syncfile
    key_path = r"Software\Classes\syncfile"

    with winreg.CreateKey(winreg.HKEY_CURRENT_USER, key_path) as key:
        winreg.SetValue(key, "", winreg.REG_SZ, "URL:SyncAgent Protocol")
        winreg.SetValueEx(key, "URL Protocol", 0, winreg.REG_SZ, "")

    # Commande √† ex√©cuter
    command_path = rf"{key_path}\shell\open\command"
    with winreg.CreateKey(winreg.HKEY_CURRENT_USER, command_path) as key:
        winreg.SetValue(key, "", winreg.REG_SZ, f'"{exe_path}" protocol "%1"')
```

#### macOS (Info.plist + LaunchServices)
```xml
<!-- Dans l'app bundle: Info.plist -->
<key>CFBundleURLTypes</key>
<array>
    <dict>
        <key>CFBundleURLName</key>
        <string>SyncAgent Protocol</string>
        <key>CFBundleURLSchemes</key>
        <array>
            <string>syncfile</string>
        </array>
    </dict>
</array>
```

```python
# Si pas d'app bundle (script Python), utiliser pyobjc
# pip install pyobjc-framework-CoreServices
from CoreServices import LSSetDefaultHandlerForURLScheme
from Foundation import NSBundle

def register_protocol_macos():
    """Enregistre syncfile:// via LaunchServices"""
    bundle_id = NSBundle.mainBundle().bundleIdentifier()
    LSSetDefaultHandlerForURLScheme("syncfile", bundle_id)
```

#### Linux (.desktop file)
```ini
# ~/.local/share/applications/syncagent-protocol.desktop
[Desktop Entry]
Name=SyncAgent Protocol Handler
Exec=/usr/local/bin/syncagent protocol %u
Type=Application
NoDisplay=true
MimeType=x-scheme-handler/syncfile;
```

```python
import subprocess
from pathlib import Path

def register_protocol_linux():
    """Enregistre syncfile:// via xdg-mime"""
    desktop_file = Path.home() / ".local/share/applications/syncagent-protocol.desktop"
    desktop_file.parent.mkdir(parents=True, exist_ok=True)

    desktop_file.write_text("""[Desktop Entry]
Name=SyncAgent Protocol Handler
Exec=/usr/local/bin/syncagent protocol %u
Type=Application
NoDisplay=true
MimeType=x-scheme-handler/syncfile;
""")

    # Enregistrer comme handler par d√©faut
    subprocess.run([
        "xdg-mime", "default",
        "syncagent-protocol.desktop",
        "x-scheme-handler/syncfile"
    ])
```

#### Handler unifi√© (CLI)
```python
# syncagent protocol "syncfile://open?path=/docs/file.txt"
import sys
from urllib.parse import urlparse, parse_qs

def handle_protocol_url(url: str):
    """Parse et ex√©cute une URL syncfile://"""
    parsed = urlparse(url)

    if parsed.scheme != "syncfile":
        raise ValueError(f"Sch√©ma invalide: {parsed.scheme}")

    action = parsed.netloc  # "open" ou "reveal"
    params = parse_qs(parsed.query)

    path = params.get("path", [None])[0]
    if not path:
        raise ValueError("Param√®tre 'path' requis")

    # V√©rifier que le path est dans le dossier sync
    full_path = get_sync_folder() / path.lstrip("/")
    if not full_path.resolve().is_relative_to(get_sync_folder()):
        raise ValueError("Path hors du dossier sync")

    if action == "open":
        open_file(full_path)
    elif action == "reveal":
        reveal_in_explorer(full_path)
```

---

## 8. WebSocket Client (Sync temps r√©el)

### 8.1 Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     WebSocket      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     WebSocket      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Laptop    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Serveur   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   Desktop   ‚îÇ
‚îÇ   (daemon)  ‚îÇ                    ‚îÇ  (FastAPI)  ‚îÇ                    ‚îÇ   (daemon)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Laptop modifie un fichier
2. Laptop upload les chunks + m√©tadonn√©es
3. Serveur broadcast "file_updated" aux autres clients WebSocket
4. Desktop re√ßoit la notif ‚Üí t√©l√©charge imm√©diatement
```

### 8.2 Connexion
```python
# Client daemon
import websockets
import asyncio

WS_URL = "wss://sync.mondomaine.com/ws"

async def connect_websocket(token: str):
    async with websockets.connect(
        WS_URL,
        extra_headers={"Authorization": f"Bearer {token}"}
    ) as ws:
        await handle_messages(ws)
```

### 8.3 Format des messages (JSON)
```python
# Serveur ‚Üí Client : Notification de changement
{
    "type": "file_updated",
    "file_id": 123,
    "path": "/docs/rapport.pdf",
    "version_id": "uuid...",
    "machine": "laptop-julien",
    "timestamp": 1704067200.0
}

# Serveur ‚Üí Client : Nouveau conflit
{
    "type": "conflict_detected",
    "file_id": 123,
    "path": "/docs/rapport.pdf",
    "branches": [
        {"machine": "laptop", "version_id": "..."},
        {"machine": "desktop", "version_id": "..."}
    ]
}

# Serveur ‚Üí Client : Fichier supprim√©
{
    "type": "file_deleted",
    "file_id": 123,
    "path": "/docs/ancien.pdf",
    "deleted_by": "laptop-julien"
}

# Client ‚Üí Serveur : Heartbeat
{
    "type": "ping"
}

# Serveur ‚Üí Client : Heartbeat response
{
    "type": "pong"
}
```

### 8.4 √âv√©nements
| Type | Direction | Description |
|------|-----------|-------------|
| `file_updated` | Serveur ‚Üí Client | Un fichier a √©t√© modifi√© par une autre machine |
| `file_deleted` | Serveur ‚Üí Client | Un fichier a √©t√© supprim√© |
| `conflict_detected` | Serveur ‚Üí Client | Nouveau conflit d√©tect√© |
| `machine_online` | Serveur ‚Üí Client | Une machine s'est connect√©e |
| `machine_offline` | Serveur ‚Üí Client | Une machine s'est d√©connect√©e |
| `ping` | Client ‚Üí Serveur | Heartbeat (toutes les 30s) |
| `pong` | Serveur ‚Üí Client | R√©ponse heartbeat |

### 8.5 Reconnexion automatique
```python
async def websocket_loop(token: str):
    """Boucle de reconnexion avec backoff exponentiel"""
    backoff = 1  # D√©lai initial en secondes
    max_backoff = 60  # D√©lai max

    while True:
        try:
            async with websockets.connect(WS_URL, ...) as ws:
                backoff = 1  # Reset apr√®s connexion r√©ussie
                await handle_messages(ws)
        except (ConnectionClosed, ConnectionRefused) as e:
            logger.warning(f"WebSocket d√©connect√©: {e}")
            await asyncio.sleep(backoff)
            backoff = min(backoff * 2, max_backoff)  # Backoff exponentiel
```

### 8.6 C√¥t√© serveur (FastAPI)
```python
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict

# Connexions actives par machine_id
active_connections: Dict[str, WebSocket] = {}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # Authentifier via token
    token = websocket.headers.get("Authorization", "").replace("Bearer ", "")
    machine = authenticate_machine(token)
    if not machine:
        await websocket.close(code=4001)
        return

    await websocket.accept()
    active_connections[machine.machine_id] = websocket

    try:
        while True:
            data = await websocket.receive_json()
            if data.get("type") == "ping":
                await websocket.send_json({"type": "pong"})
    except WebSocketDisconnect:
        del active_connections[machine.machine_id]

async def broadcast_to_others(source_machine_id: str, message: dict):
    """Envoie un message √† tous les clients sauf la source"""
    for machine_id, ws in active_connections.items():
        if machine_id != source_machine_id:
            await ws.send_json(message)
```

### 8.7 Flux complet (temps r√©el)
```
1. Laptop: File watcher d√©tecte modification
2. Laptop: Debounce 250ms + d√©lai 3s
3. Laptop: Upload chunks chiffr√©s
4. Laptop: POST /api/files (m√©tadonn√©es)
5. Serveur: Enregistre la nouvelle version
6. Serveur: broadcast_to_others("file_updated", {...})
7. Desktop: Re√ßoit notification WebSocket
8. Desktop: GET /api/files/{id} + t√©l√©charge chunks
9. Desktop: D√©chiffre et √©crit le fichier
10. Sync compl√®te en < 5s (selon taille fichier)
```

### 8.8 Reconnexion apr√®s offline (catch-up)

Quand un client revient apr√®s une d√©connexion (quelques heures, jours...) :

#### √âtat local persist√©
```json
// ~/.syncagent/state.json
{
  "last_sync_at": 1704067200.0,
  "last_server_version": 42,
  "pending_uploads": ["/docs/local-edit.txt"]
}
```

#### Flux de reconnexion
```
1. Client reconnecte WebSocket
2. Client: GET /api/changes?since=<last_sync_at>
3. Serveur retourne tous les changements depuis cette date
4. Client t√©l√©charge les fichiers modifi√©s/cr√©√©s
5. Client supprime localement les fichiers supprim√©s
6. Client push ses modifications locales (pending_uploads)
7. D√©tection de conflits si n√©cessaire
8. Mise √† jour de last_sync_at
```

#### API endpoint
```python
@app.get("/api/changes")
def get_changes(since: float, machine_id: str):
    """Retourne tous les changements depuis un timestamp"""
    changes = []

    # Fichiers modifi√©s/cr√©√©s (par d'autres machines)
    updated = db.execute("""
        SELECT f.id, f.path, v.id as version_id, v.machine_id, f.updated_at
        FROM files f
        JOIN versions v ON f.current_version_id = v.id
        WHERE f.updated_at > ?
        AND v.machine_id != ?
        AND f.is_deleted = FALSE
    """, (since, machine_id)).fetchall()

    for row in updated:
        changes.append({
            "type": "updated",
            "file_id": row['id'],
            "path": row['path'],
            "version_id": row['version_id'],
            "updated_at": row['updated_at']
        })

    # Fichiers supprim√©s
    deleted = db.execute("""
        SELECT id, path, deleted_at
        FROM files
        WHERE is_deleted = TRUE
        AND deleted_at > ?
    """, (since,)).fetchall()

    for row in deleted:
        changes.append({
            "type": "deleted",
            "file_id": row['id'],
            "path": row['path'],
            "deleted_at": row['deleted_at']
        })

    return {
        "changes": sorted(changes, key=lambda x: x.get('updated_at') or x.get('deleted_at')),
        "server_time": time.time()
    }
```

#### Gestion des modifications locales pendant offline
```python
async def reconnect_sync():
    """Sync compl√®te apr√®s reconnexion"""
    state = load_local_state()

    # 1. R√©cup√©rer les changements serveur
    changes = await api.get_changes(since=state['last_sync_at'])

    # 2. Appliquer les changements distants
    for change in changes['changes']:
        if change['type'] == 'updated':
            await download_and_apply(change)
        elif change['type'] == 'deleted':
            delete_local_file(change['path'])

    # 3. Push les modifications locales (peut cr√©er des conflits)
    for path in state.get('pending_uploads', []):
        await sync_file(path)

    # 4. Mettre √† jour l'√©tat
    state['last_sync_at'] = changes['server_time']
    state['pending_uploads'] = []
    save_local_state(state)
```

#### Cas de conflit post-reconnexion
Si le client a modifi√© un fichier localement ET ce fichier a √©t√© modifi√© sur le serveur :
- Le serveur d√©tecte le conflit (parent_version_id != current_version_id)
- Cr√©ation des fichiers conflits comme d'habitude
- L'utilisateur r√©sout manuellement

---

## 9. S√©curit√© R√©capitulatif

| Sc√©nario d'attaque | R√©sultat |
|--------------------|----------|
| Hack du serveur API | Acc√®s m√©tadonn√©es seulement, pas de contenu |
| Hack de la base de donn√©es | M√©tadonn√©es structurelles, pas de contenu |
| Hack du block storage OVH | Blocs chiffr√©s, inutilisables |
| Interception HTTPS (MITM) | Blocs chiffr√©s, inutilisables |
| Vol du token d'API | Upload/delete possible, mais pas de lecture |
| Vol de la cl√© E2EE seule | Impossible d'acc√©der au serveur |
| Acc√®s physique √† une machine | Compromission (mais limit√© √† cette machine) |

---

## 10. T√¢ches d'impl√©mentation

### Phase 1: Crypto & Core
- [ ] Fonction de d√©rivation de cl√© (Argon2id)
- [ ] Chiffrement/d√©chiffrement AES-GCM
- [ ] Stockage s√©curis√© de la cl√© locale
- [ ] CLI: `init`, `unlock`, `export-key`, `import-key`

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : d√©rivation de cl√© avec vecteurs de test connus
- [ ] Tests unitaires : chiffrement/d√©chiffrement (round-trip, edge cases)
- [ ] Tests unitaires : stockage cl√© (keyring mock, fallback file)
- [ ] Tests CLI : `init`, `unlock`, `export-key`, `import-key` (subprocess ou click testing)
- [ ] Mypy strict sur tous les modules crypto
- [ ] Ruff zero warnings
- [ ] Coverage ‚â• 95%

### Phase 2: Content-Defined Chunking (CDC)
- [ ] Impl√©mentation CDC avec rolling hash (FastCDC ou Rabin)
- [ ] Taille moyenne ~4 MB, min 1 MB, max 8 MB
- [ ] Hash SHA-256 des blocs
- [ ] Upload/download blocs chiffr√©s
- [ ] Liaison chunks ‚Üí fichier (pas de d√©duplication inter-fichiers en v1)

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : chunking avec fichiers de diff√©rentes tailles (0, 1B, 1MB, 10MB, 100MB)
- [ ] Tests unitaires : stabilit√© des fronti√®res (insertion au milieu ne change pas les autres chunks)
- [ ] Tests unitaires : hash SHA-256 coh√©rent entre runs
- [ ] Tests int√©gration : upload/download round-trip
- [ ] Benchmark : performance chunking sur gros fichiers
- [ ] Mypy strict + Ruff zero warnings
- [ ] Coverage ‚â• 95%

### Phase 3: Serveur M√©tadonn√©es
- [ ] FastAPI app + SQLite WAL
- [ ] API REST (auth, files, chunks, conflicts)
- [ ] D√©tection de conflits (version parente)
- [ ] Authentification par token

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : chaque endpoint API (auth, files, chunks, conflicts, trash)
- [ ] Tests unitaires : d√©tection de conflits (cas lin√©aire, cas divergent)
- [ ] Tests unitaires : validation tokens (valide, expir√©, invalide)
- [ ] Tests unitaires : invitations (cr√©ation, usage unique, expiration)
- [ ] Tests int√©gration : workflow complet (register ‚Üí upload ‚Üí download)
- [ ] Tests : background jobs (purge trash, cleanup sessions)
- [ ] Mypy strict + Ruff zero warnings
- [ ] Coverage ‚â• 95% (hors templates Web UI)

### Phase 4: Block Storage
- [ ] Int√©gration OVH S3/Swift (boto3)
- [ ] Upload/download blocs
- [ ] Suppression chunks √† la purge de corbeille (simple, pas de GC complexe)

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : LocalFSStorage (put, get, exists, delete, delete_by_file)
- [ ] Tests unitaires : S3Storage avec moto (mock S3)
- [ ] Tests : factory create_storage()
- [ ] Tests int√©gration : round-trip complet (upload ‚Üí download ‚Üí verify)
- [ ] Mypy strict + Ruff zero warnings
- [ ] Coverage ‚â• 95%

### Phase 5: Sync Engine
- [ ] File watcher (watchdog)
- [ ] Algorithme de sync (push/pull)
- [ ] Gestion des conflits (duplication)
- [ ] SQLite local pour √©tat

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : file watcher (cr√©ation, modification, suppression, renommage)
- [ ] Tests unitaires : debounce et d√©lai 3s
- [ ] Tests unitaires : d√©tection changements locaux vs DB
- [ ] Tests unitaires : cr√©ation fichiers conflit (nommage correct)
- [ ] Tests unitaires : gestion fichiers verrouill√©s (Windows mock)
- [ ] Tests int√©gration : sync bidirectionnelle compl√®te
- [ ] Mypy strict + Ruff zero warnings
- [ ] Coverage ‚â• 95%

### Phase 6: Web UI
- [ ] File browser (m√©tadonn√©es seulement)
- [ ] Liste des conflits
- [ ] R√©solution de conflits
- [ ] Status des machines
- [ ] Liens `syncfile://`

**Tests & Qualit√© (TDD) :**
- [ ] Tests : setup wizard (redirection, cr√©ation admin, validation password)
- [ ] Tests : CSRF protection
- [ ] Tests : session cookies (HttpOnly, Secure, expiration)
- [ ] Tests fonctionnels : navigation, recherche (httpx TestClient)
- [ ] Note : templates HTML exclus de l'objectif coverage
- [ ] Mypy strict + Ruff zero warnings

### Phase 7: Protocol Handler
- [ ] Parsing URL
- [ ] Enregistrement Windows/macOS/Linux
- [ ] Int√©gration Web UI

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : parsing URLs syncfile:// (valides et invalides)
- [ ] Tests unitaires : validation machine_id et path
- [ ] Tests unitaires : s√©curit√© (path traversal, injection)
- [ ] Tests : enregistrement protocol (mocks registry/plist/xdg)
- [ ] Mypy strict + Ruff zero warnings
- [ ] Coverage ‚â• 95%

### Phase 8: Tray Icon
- [ ] pystray setup
- [ ] Ic√¥nes par √©tat
- [ ] Menu contextuel

**Tests & Qualit√© (TDD) :**
- [ ] Tests unitaires : √©tat icon (idle, syncing, error, conflict)
- [ ] Tests unitaires : menu actions (callbacks)
- [ ] Note : tray icon exclu de l'objectif coverage (GUI)
- [ ] Mypy strict + Ruff zero warnings

---

**Note M√©thodologie TDD :**
Chaque phase inclut maintenant ses propres tests et crit√®res de qualit√©. L'approche recommand√©e est :
1. √âcrire les tests d'abord (red)
2. Impl√©menter le code minimal pour passer les tests (green)
3. Refactorer si n√©cessaire (refactor)
4. V√©rifier mypy strict + ruff avant chaque commit
5. Maintenir coverage ‚â• 95% tout au long du d√©veloppement

---

## 11. Stack Technique

| Composant | Technologie |
|-----------|-------------|
| Client | Python 3.11+ |
| Crypto | cryptography (AES-GCM), argon2-cffi |
| File watcher | watchdog |
| HTTP client | httpx ou requests |
| DB locale | SQLite |
| Tray icon | pystray + Pillow |
| Serveur | FastAPI + Jinja2 + HTMX |
| CSS | Pico CSS |
| DB serveur | SQLite WAL |
| Block storage | OVH S3 (boto3) |
| Auth | JWT ou tokens simples |

---

## 12. Avantages de cette Architecture

| Aspect | B√©n√©fice |
|--------|----------|
| **Zero Knowledge** | Le serveur ne peut JAMAIS lire les fichiers |
| **Hack-proof** | M√™me un hack total du serveur = 0 fuite de donn√©es |
| **HTTPS simple** | Plus besoin de SSH, d√©ploiement facile |
| **Scalable** | Block storage = stockage illimit√©, pas cher |
| **CDC optimis√©** | Modifications partielles = peu de donn√©es transf√©r√©es |
| **Architecture simple (v1)** | Pas de GC complexe, suppression directe √† la purge |
| **Multi-device** | M√™me cl√© E2EE = acc√®s sur toutes les machines |
| **Conflits simples** | Duplication automatique, r√©solution manuelle |
| **√âvolutif** | D√©duplication inter-fichiers pr√©vue en v2 |

---

## Appendix A: D√©tails techniques compl√©mentaires

### A.1 Limites

| Limite | Valeur | Note |
|--------|--------|------|
| Taille max fichier | 1 TB | Limite pratique S3 multipart |
| Nom de fichier | 255 caract√®res | Standard FS |
| Profondeur chemin | 4096 caract√®res | Standard FS |
| Machines par compte | Illimit√© | - |
| Session admin | 24h (configurable) | - |
| Invitation token | 24h (expire) | Usage unique |
| Corbeille r√©tention | 30j (configurable) | - |

### A.2 Fichiers et dossiers sp√©ciaux

#### Dossiers vides
- Les dossiers vides sont synchronis√©s via `files.is_directory = TRUE`
- Pas de chunks associ√©s (`current_version_id = NULL`)
- Suppression : si le dossier devient non-vide (fichiers ajout√©s), passage √† `is_directory = FALSE`

#### Liens symboliques (symlinks)
- **Ignor√©s compl√®tement** (comportement par d√©faut)
- Rationale : √©vite les boucles infinies et les probl√®mes de s√©curit√©
- Le file watcher ignore les symlinks
- Pas de sync des liens, pas d'erreur

#### D√©tection des renommages
- Impl√©ment√© via les chunk_hashes
- Si un fichier dispara√Æt et un nouveau fichier appara√Æt avec les m√™mes chunk_hashes :
  - D√©tection de renommage ‚Üí mise √† jour du path, pas de re-upload
  - Optimisation c√¥t√© client avant upload

```python
def detect_rename(disappeared_files: list, new_files: list) -> list[tuple]:
    """D√©tecte les renommages via correspondance de chunks"""
    renames = []

    for old_file in disappeared_files:
        old_hashes = set(old_file.chunk_hashes)
        for new_file in new_files:
            new_hashes = set(new_file.chunk_hashes)
            # Si tous les chunks correspondent ‚Üí renommage
            if old_hashes == new_hashes:
                renames.append((old_file.path, new_file.path))
                break

    return renames
```

### A.3 Gestion des fichiers verrouill√©s (Windows)

Sur Windows, certains fichiers peuvent √™tre verrouill√©s par d'autres applications (Excel, Word, etc.).

**Strat√©gie : Skip & Retry avec backoff**

```python
import time
from typing import Optional

MAX_LOCK_RETRIES = 5
LOCK_RETRY_DELAYS = [1, 2, 5, 10, 30]  # Secondes, backoff progressif

def try_read_file(file_path: str) -> Optional[bytes]:
    """Tente de lire un fichier, avec retry si verrouill√©"""
    for attempt in range(MAX_LOCK_RETRIES):
        try:
            with open(file_path, 'rb') as f:
                return f.read()
        except PermissionError:
            # Fichier verrouill√©
            if attempt < MAX_LOCK_RETRIES - 1:
                delay = LOCK_RETRY_DELAYS[min(attempt, len(LOCK_RETRY_DELAYS) - 1)]
                logger.warning(f"File locked: {file_path}, retrying in {delay}s")
                time.sleep(delay)
            else:
                logger.error(f"File still locked after {MAX_LOCK_RETRIES} attempts: {file_path}")
                return None
    return None

def sync_with_lock_handling(file_path: str):
    """Sync avec gestion des fichiers verrouill√©s"""
    data = try_read_file(file_path)

    if data is None:
        # Fichier verrouill√© ‚Üí ajouter √† pending_uploads pour retry ult√©rieur
        mark_pending_upload(file_path, error="File locked by another process")
        # Notification tray icon
        notify_user(f"Fichier verrouill√©, sync diff√©r√©e : {file_path}")
        return False

    # Continuer avec la sync normale
    return sync_file_data(file_path, data)
```

**Comportement :**
1. Premier essai imm√©diat
2. Si verrouill√© : retry apr√®s 1s, 2s, 5s, 10s, 30s
3. Si toujours verrouill√© apr√®s 5 tentatives :
   - Fichier marqu√© comme "pending_upload" avec erreur
   - Notification utilisateur (tray icon)
   - Retry automatique au prochain scan (5 min)

### A.4 Configuration WebSocket (heartbeat/timeout)

```json
// config.json (client)
{
  "websocket": {
    "heartbeat_interval": 30,    // Secondes entre chaque ping (d√©faut: 30)
    "reconnect_min_delay": 1,    // D√©lai min reconnexion (d√©faut: 1s)
    "reconnect_max_delay": 60    // D√©lai max reconnexion (d√©faut: 60s)
  }
}

// config.json (serveur)
{
  "websocket": {
    "timeout": 90,               // Ferme si pas de ping depuis X secondes (d√©faut: 3x heartbeat)
    "max_connections": 100       // Limite de connexions simultan√©es (d√©faut: 100)
  }
}
```

**Valeurs recommand√©es :**
- `heartbeat_interval`: 30s (√©quilibre entre r√©activit√© et overhead)
- `timeout`: 90s (3x heartbeat, tol√®re 2 pings manqu√©s)
- `reconnect_min_delay`: 1s (r√©activit√© apr√®s d√©connexion br√®ve)
- `reconnect_max_delay`: 60s (√©vite spam sur serveur down)

### A.5 Daemon Single Instance (PID file + Lock)

Le daemon ne doit s'ex√©cuter qu'une seule fois par machine. Si un deuxi√®me processus tente de d√©marrer, il doit d√©tecter l'instance existante et refuser de se lancer proprement.

**Approche : PID file avec file locking (state of the art cross-platform)**

```python
import sys
import os
import fcntl  # Unix only - voir alternative Windows ci-dessous
from pathlib import Path

class SingleInstanceLock:
    """Garantit qu'une seule instance du daemon tourne"""

    def __init__(self, lock_file: Path):
        self.lock_file = lock_file
        self.lock_fd = None

    def acquire(self) -> bool:
        """
        Tente d'acqu√©rir le lock.
        Retourne True si succ√®s, False si une autre instance tourne.
        """
        self.lock_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            self.lock_fd = open(self.lock_file, 'w')
            if sys.platform == 'win32':
                import msvcrt
                msvcrt.locking(self.lock_fd.fileno(), msvcrt.LK_NBLCK, 1)
            else:
                fcntl.flock(self.lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)

            # √âcrire le PID pour debug
            self.lock_fd.write(str(os.getpid()))
            self.lock_fd.flush()
            return True

        except (IOError, OSError):
            # Lock d√©j√† acquis par une autre instance
            if self.lock_fd:
                self.lock_fd.close()
                self.lock_fd = None
            return False

    def release(self):
        """Lib√®re le lock"""
        if self.lock_fd:
            try:
                if sys.platform == 'win32':
                    import msvcrt
                    msvcrt.locking(self.lock_fd.fileno(), msvcrt.LK_UNLCK, 1)
                else:
                    fcntl.flock(self.lock_fd, fcntl.LOCK_UN)
            finally:
                self.lock_fd.close()
                self.lock_fd = None
                # Supprimer le fichier de lock
                try:
                    self.lock_file.unlink()
                except OSError:
                    pass

    def __enter__(self):
        if not self.acquire():
            raise RuntimeError("Another instance is already running")
        return self

    def __exit__(self, *args):
        self.release()


# Usage dans le daemon
def start_daemon():
    """D√©marre le daemon avec protection single instance"""
    lock_file = Path.home() / ".syncagent" / "daemon.lock"
    lock = SingleInstanceLock(lock_file)

    if not lock.acquire():
        print("Error: SyncAgent daemon is already running.", file=sys.stderr)
        print("Use 'syncagent status' to check the current daemon.", file=sys.stderr)
        sys.exit(1)

    try:
        # D√©marrer le daemon normalement
        run_daemon()
    finally:
        lock.release()
```

**Comportement :**
- Au d√©marrage : tente d'acqu√©rir un file lock exclusif sur `~/.syncagent/daemon.lock`
- Si le lock √©choue : message d'erreur clair et exit code 1
- Si le lock r√©ussit : √©criture du PID et d√©marrage du daemon
- √Ä l'arr√™t : lib√©ration du lock et suppression du fichier

**Avantages de cette approche :**
- Cross-platform (Windows, macOS, Linux)
- R√©sistant aux crashes (le lock est lib√©r√© automatiquement par l'OS)
- Pas de stale PID file (le lock garantit que le processus tourne vraiment)
- Simple et robuste

### A.6 Permissions des fichiers

**Les permissions (mode Unix / ACL Windows) ne sont PAS synchronis√©es.**

Rationale :
- Les permissions varient entre OS (chmod vs ACL)
- Les UID/GID ne correspondent pas entre machines
- Le serveur est Zero-Knowledge (ne devrait pas stocker des m√©tadonn√©es sensibles)
- Cas d'usage principal : documents utilisateur (permissions standard suffisent)

**Comportement :**
- √Ä l'upload : les permissions locales sont ignor√©es
- Au download : le fichier est cr√©√© avec les permissions par d√©faut (umask sur Unix)
- Les fichiers gardent les permissions de l'utilisateur qui ex√©cute le daemon

**Note :** Si une synchronisation de permissions est n√©cessaire, c'est envisageable en v2 via des m√©tadonn√©es optionnelles.